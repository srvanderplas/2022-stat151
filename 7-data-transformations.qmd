# Data Transformations

```{r data-transform-setup, include = F}
# Need an r chunk to use the R engine, otherwise defaults to
# jupyter even with the flag set in _quarto.yml
c()
knitr::opts_chunk$set(collapse = T, message = F)
```


> Happy families are all alike; every unhappy family is unhappy in its own way. - Leo Tolstoy

> Tidy datasets are all alike, but every messy dataset is messy in its own way. - Hadley Wickham


Most of the time, data does not come in a format suitable for analysis. Spreadsheets are generally optimized for data *viewing*, rather than for statistical analysis - they may be laid out so that there are multiple observations in a single row (e.g., commonly a year's worth of data, with monthly observations in each column).

Unfortunately, this type of data structure is not usually useful to us when we analyze or visualize the data.


## Identifying the problem: Messy data

```{r tidy-package-setup, message = F, warning = F}
library(dplyr) # Data wrangling
library(tidyr) # Data rearranging
library(tibble) # data table
```

These datasets all display the same data: TB cases documented by the WHO in Afghanistan, Brazil, and China, between 1999 and 2000. There are 4 variables: country, year, cases, and population, but each table has a different layout.

```{r tidy1, echo = F}
knitr::kable(table1, caption = "Table 1")
```

Here, each observation is a single row, each variable is a column, and everything is nicely arranged for e.g. regression or statistical analysis. We can easily compute another measure, such as cases per 100,000 population, by taking cases/population * 100000 (this would define a new column).


```{r tidy2, echo = F}
knitr::kable(table2, caption = "Table 2")
```

Here, we have 4 columns again, but we now have 12 rows: one of the columns is an indicator of which of two numerical observations is recorded in that row; a second column stores the value. This form of the data is more easily plotted in e.g. ggplot2, if we want to show lines for both cases and population, but computing per capita cases would be much more difficult in this form than in the arrangement in table 1.


In this form, we have two tables - one for population, and one for cases. Each year's observations are in a separate column. This format is often found in separate sheets of an excel workbook. To work with this data, we'll need to transform each table so that there is a column indicating which year an observation is from, and then merge the two tables together by country and year.


```{r tidy3, echo = F}
knitr::kable(table3, caption = "Table 3")
```

This form has only 3 columns, because the rate variable (which is a character) stores both the case count and the population. We can't do *anything* with this format as it stands, because we can't do math on data stored as characters. However, this form might be easier to read and record for a human being.


```{r tidy4, echo = F}
knitr::kable(table4a, caption = "Table 4a")
knitr::kable(table4b, caption = "Table 4b")
```

```{r tidy5, echo = F}
knitr::kable(table5, caption = "Table 5")
```

Table 5 is very similar to table 3, but the year has been separated into two columns - century, and year. This is more common with year, month, and day in separate columns  (or date and time in separate columns), often to deal with the fact that spreadsheets don't always handle dates the way you'd hope they would.


These variations highlight the principles which can be said to define a tidy dataset:
1. Each variable must have its own column
2. Each observation must have its own row
3. Each value must have its own cell

<div class="tryitout">

### Try it out {-}
Go back through the 5 tables and determine whether each table is tidy, and if it is not, which rule or rules it violates. Figure out what you would have to do in order to compute a standardized TB infection rate per 100,000 people.

<details><summary>Solution</summary>

1. table1 - this is tidy data. Computing a standardized infection rate is as simple as creating the variable rate = cases/population*100,000.

2. table2 - each variable does not have its own column (so a single year's observation of one country actually has 2 rows). Computing a standardized infection rate requires moving cases and population so that each variable has its own column, and then you can proceed using the process in 1.

3. table3 - each value does not have its own cell (and each variable does not have its own column). In Table 3, you'd have to separate the numerator and denominator of each cell, convert each to a numeric variable, and then you could proceed as in 1.

4. table4a and table 4b - there are multiple observations in each row because there is not a column for year. To compute the rate, you'd need to "stack" the two columns in each table into a single column, add a year column that is 1999, 1999, 1999, 2000, 2000, 2000, and then merge the two tables. Then you could proceed as in 1.

5. table 5 - each variable does not have its own column (there are two columns for year, in addition to the issues noted in table3). Computing the rate would be similar to table 3; the year issues aren't actually a huge deal unless you plot them, at which point 99 will seem to be bigger than 00 (so you'd need to combine the two year columns together first).

</details>

</div>

It is actually impossible to have a table that violates only one of the rules of tidy data - you have to violate at least two. So a simpler way to state the rules might be:

1. Each dataset goes into its own table
2. Each variable gets its own column

By the end of this course, you should have the skills to "tidy" each of these tables.

## Pivot operations

It's fairly common for data to come in forms which are convenient for either human viewing or data entry. Unfortunately, these forms aren't necessarily the most friendly for analysis. 

![Image showing wide format and long format tables containing the same data. Image from https://github.com/kelseygonzalez/tidyexplain.](https://raw.githubusercontent.com/kelseygonzalez/tidyexplain/master/images/static/png/original-dfs-tidy.png)

The two operations we'll learn here are wide -> long and long -> wide. 

![GIF showing the transition from wide format to long format and back using pivot_wider and pivot_longer commands. Image from https://github.com/kelseygonzalez/tidyexplain.](https://raw.githubusercontent.com/kelseygonzalez/tidyexplain/wider_longer/images/tidyr-pivot_wider_longer.gif)

This animation uses the R functions pivot_wider() and pivot_longer() [Animation source](https://github.com/kelseygonzalez/tidyexplain/tree/wider_longer), but the concept is the same in both R and python. 

### Longer

In many cases, the data come in what we might call "wide" form - some of the column names are not names of variables, but instead, are themselves values of another variable. 

Tables 4a and 4b are good examples of data which is in "wide" form and should be in long(er) form: the years, which are variables, are column names, and the values are cases and population respectively.  

```{r longer-pivot-demo}
table4a
table4b
```

The solution to this is to rearrange the data into "long form": to take the columns which contain values and "stack" them, adding a variable to indicate which column each value came from. To do this, we have to duplicate the values in any column which isn't being stacked (e.g. country, in both the example above and the image below). 

```{r tidyr-pivot-longer-pic, echo = F, out.width = "50%", fig.cap = "A visual representation of what the pivot_longer operation looks like in practice."}
knitr::include_graphics("images/tidyr_pivot_longer.png")
```

Once our data are in long form, we can (if necessary) separate values that once served as column labels into actual variables, and we'll have tidy(er) data. 

#### Manual Method {.ex}

We can do the wide-to-long transition manually, and doing so is actually instructive.

Consider the following table of average daily temperatures observed in Lincoln, NE in January 2022. This data is recorded in human-friendly form, in the approximate shape of a calendar. Each week has its own row, and each day has its own column.

![Initial data table](images/manual-wide-to-long-table.png)

Open up the [spreadsheet](data/2022-temperatures-lincoln.xlsx) containing this table on your computer and let's work through converting it to long format together. 

<details><summary>
To convert this data to long format, the first thing we need to do is create a new column: Day_of_Week
</summary>

![Adding Day_of_Week column](images/manual-wide-to-long-table-1.png)

</details>

<details><summary>
Then, we need to create a temperature column to hold the daily average temperature values.
</summary>

![Adding Temperature column](images/manual-wide-to-long-table-2.png)
</details>

<details><summary>
Now that we have the 3 columns our data will fit into set up, we can start moving data over.
</summary>

First, we will repeat Sunday for each of the first 5 rows in Column B, copying the values from column D into the Temperature column (Column C). Once that is done, we delete the Sunday column from our dataset to prevent duplication.

![Copying Sunday into Column B](images/manual-wide-to-long-table-3.png)

![Copying Temperature into Column C](images/manual-wide-to-long-table-4.png)

![Deleting data to prevent duplication](images/manual-wide-to-long-table-5.png)

</details>

<details><summary>
Duplicating repeated data and moving Monday data over
</summary>
We then duplicate the 5 week values, so that we can move another column of data over into our long format table.

![Duplicating Week 1-5 values](images/manual-wide-to-long-table-6.png)

![Copying Monday into Column B](images/manual-wide-to-long-table-7.png)

![Copying Temperature into Column C](images/manual-wide-to-long-table-8.png)

![Deleting data to prevent duplication](images/manual-wide-to-long-table-9.png)

</details>


<details><summary>
Duplicating repeated data and moving Tuesday data over
</summary>
We then duplicate the 5 week values, so that we can move another column of data over into our long format table.

![Duplicating Week 1-5 values](images/manual-wide-to-long-table-10.png)

![Copying Tuesday into Column B](images/manual-wide-to-long-table-11.png)

![Copying Temperature into Column C](images/manual-wide-to-long-table-12.png)

![Deleting data to prevent duplication](images/manual-wide-to-long-table-13.png)

</details>

<details><summary>
Repeat these steps for each additional column
</summary>


![Wednesday data](images/manual-wide-to-long-table-14.png)

![Thursday data](images/manual-wide-to-long-table-15.png)

This process is repeated for the additional days, resulting in a final data set that looks like this:

![Final (long) data set](images/manual-wide-to-long-table-16.png)

</details>

<details><summary>
Arranging the data for plotting
</summary>

To do something useful with this data, we might want to sort by Week number to get a chronological ordering of the temperature values:

![Sorted by Week](images/manual-wide-to-long-table-17.png)

We could even add a new variable, Day_of_Year, which would make it much easier to plot. We have data starting January 1, so in this case, the day component of the date is also the day of the year.

![Adding Day of Year](images/manual-wide-to-long-table-18.png)

![Plotting the Data](images/manual-wide-to-long-table-19.png)

</details>

You may at this point be wondering why we don't just do this operation by hand... and it's because copy-paste isn't reproducible. I can't guarantee that whomever did the copy-paste operation clicked on the correct cell in the spreadsheet, selected the correct values, and so on. But when I run the same code on the same file, I can be much more certain that I'll get the same results.

(Also, it takes forever to do the copy-paste operations manually, and I'm sure you have better ways to use your valuable time!)

#### Computational Approach

In order to move from wide format to long format, we need to specify at least 2 of 3 possible quantities:

1. The values to keep to determine rows (the key)    
![The values determine which rows are unique](images/pivot-specification-key.png)

2. The columns to merge into "long" form, where the column names are stored as a new variable    
![The column names are turned into values of a new "label" column](images/pivot-specification-columns.png)

3. The values of interest    
![The value of interest is transformed into a new (long) single column](images/pivot-specification-values.png)

For most simple cases, if we have 2 of these 3 things, the pivot operation will go on as planned. Sadly, python and R require different defaults for which things are necessary, even if the fundamental operation is the same in each language.


<!-- https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.pivot.html -->

<details><summary>Conversion using wide-to-long and merge/join statements in R</summary>

```{r tidyr-pivot-longer-demo2}
tba <- table4a %>% 
  pivot_longer(-country, names_to = "year", values_to = "cases")
tbb <- table4b %>% 
  pivot_longer(-country, names_to = "year", values_to = "population")

# To get the tidy data, we join the two together
# merging by country and year
left_join(tba, tbb, by = c("country", "year")) %>%
  # make year numeric b/c it's dumb not to
  mutate(year = as.numeric(year))

```

The columns are moved to a variable with the name passed to the argument "names_to" (hopefully, that is easy to remember), and the values are moved to a variable with the name passed to the argument "values_to" (again, hopefully easy to remember). 

We identify ID variables (variables which we don't want to pivot) by not including them in the pivot statement. We can do this in one of two ways:

- select only variables we want to pivot: `pivot_longer(table4a, cols = `1999`:`2000`, names_to = "year", values_to = "cases")`
- select variables we don't want to pivot, using `-` to remove them. (see above, where `-country` excludes country from the pivot operation)

Which option is easier depends how many things you're pivoting (and how the columns are structured). 
</details>

<details><summary>Some notes on selecting variables in R</summary>
Note: These details really only apply to the `tidyverse` - a series of R packages including `dplyr` and `tidyr`, among others.

There are many different ways you can select variables in tidyverse functions:

- a character vector of column names passed to helper functions `all_of` and `any_of`. `all_of` will throw an error if something in the vector is missing, `any_of` will select anything that matches an entry in the vector but won't error out if it doesn't find some variable.

- Using a pattern, such as `starts_with`, `ends_with`, `contains`, `matches`, and `num_range`. These functions take a single character string as an argument and select all columns that match the character string in the way indicated by the function name.

- `everything` matches all variables

- `last_col` matches the last column

You can also use logical operators `!` (taking the complement), `&` and `|` (and/or), `c()` to combine selections, and `:` to select a range of consecutive variables.

```{r iris-selection-demo}
data(iris)

library(tidyselect) # this is the library with all of the functions described above
# it is automatically loaded with dplyr, tidyr, etc.

head(iris)
iris %>% select(matches("Sepal"))
iris %>% select(!matches("Sepal"))
iris %>% select(ends_with("Width"))

iris %>% select(Sepal.Length:Petal.Length)
```

These selection helpers can be extremely useful when choosing columns to pivot.

</details>

<details><summary>Conversion using wide-to-long and merge/join statements in Python</summary>
A similar operation can be done  in python using pd.melt. Think of "melting" your data down from a metal object to a liquid. (There actually used to be an R package that used cast/melt as the terms for pivot wider/longer, but it has been superseded by pivot_wider and pivot_longer syntax).

As in R, we identify the variables that we DON'T want to pivot, but in python syntax, these are called id_vars. Then, as in R, we need to specify the names of the columns we want to have at the end. In Python, we also have to specify value variables: variables that we will be pivoting (so we specify both those we are pivoting and those we aren't). Remember, id_vars are variables that we would copy-paste over and over with each set of variables in the manual pivot operation, where value_vars are the set of columns we want to combine into variable:value pairs. 

```{python pivot-longer-demo-python}
import pandas as pd
table4a = r.table4a # get variable from R within python
table4b = r.table4b

tba = pd.melt(table4a, id_vars = ['country'], 
                       value_vars = ['1999', '2000'], 
                       var_name = 'year', 
                       value_name = 'cases')
tbb = pd.melt(table4a, id_vars = ['country'], 
                       value_vars = ['1999', '2000'], 
                       var_name = 'year', 
                       value_name = 'population')

final = pd.merge(tba, tbb, on= ['country', 'year'])
# convert year to numeric from string
final["year"] = pd.to_numeric(final["year"])

final
```

</details>


<details><summary>Conversion using new variables, appending tables, and wide-to-long statements in R</summary>

If we wanted to avoid the table join, we could do this process another way: first, we would add a column to each tibble called id with values "cases" and "population" respectively. Then, we could bind the two tables together by row (so stack them on top of each other). We could then do a wide-to-long pivot, followed by a long-to-wide pivot to get our data into tidy form. 

```{r tidyr-pivot-longer-id}
# Create ID columns
table4a.x <- table4a %>% mutate(id = "cases")
table4b.x <- table4b %>% mutate(id = "population")
# Create one table
table4 <- bind_rows(table4a.x, table4b.x)

table4_long <- table4 %>%
  # rearrange columns
  select(country, id, `1999`, `2000`) %>%
  # Don't pivot country or id
  pivot_longer(-c(country:id), names_to = "year", values_to = "count")

# Intermediate fully-long form
table4_long

# make wider, with case and population columns
table4_tidy <- table4_long %>%
  pivot_wider(names_from = id, values_from = count)

table4_tidy
```

</details>


<details><summary>Conversion using new variables, appending tables, and wide-to-long statements in Python</summary>

If we wanted to avoid the table join, we could do this process another way: first, we would add a column to each tibble called id with values "cases" and "population" respectively. Then, we could bind the two tables together by row (so stack them on top of each other). We could then do a wide-to-long pivot, followed by a long-to-wide pivot to get our data into tidy form. 

```{python pivot-longer-id-python}
# Create ID columns
table4a_x = r.table4a.assign(id= "cases")
table4b_x = r.table4b.assign(id = "population")

# Create one table
table4 = pd.concat([table4a_x, table4b_x])
table4

table4_long = pd.melt(table4, 
                      id_vars = ['country', 'id'], 
                      value_vars = ['1999', '2000'], 
                      var_name = 'year')

# Intermediate fully-long form
table4_long

# make wider, with case and population columns
# Index is the columns we want to keep that ID a unique combination of variables
# Columns are the columns that become new labels
# There should be a single value for each combination of index and the column variable(s)
table4_tidy = pd.pivot(table4_long, 
                       index = ['country', 'year'],  
                       columns = ['id'], 
                       values = 'value')

table4_tidy

table4_tidy.reset_index() # to remove the index if you want the normal data table
```

We will talk more about long-to-wide pivot operations below. For now, it's enough to know that the long-to-wide operation can be useful in getting your data into tidy form.

</details>


Transitioning from wide data to long data isn't too complicated in most situations -- and it definitely beats doing that operation by hand, even for short, simple tables. 

It takes some getting used to, but once you get a feel for how to do these operations, you'll be able to handle messy data reproducibly - instead of describing how you did XYZ operations in Excel, you can provide a script that will take the original data as input and spit out clean, analysis-ready data as output. 

::: warning
Because wide-to-long transformations end up combining values from several columns into a single column, you can run into issues with type conversions that happen implicitly. If you try to `pivot_longer()` using a character column mixed in with numeric columns, your "value" column will be converted to a character automatically. 
:::


### Wider

While it's very common to need to transform data into a longer format, it's not that uncommon to need to do the reverse operation. When an observation is scattered across multiple rows, your data is too long and needs to be made wider again.  

Table 2 is an example of a table that is in long format but needs to be converted to a wider layout to be "tidy" - there are separate rows for cases and population, which means that a single observation (one year, one country) has two rows. 


```{r pivot-wider-pic, echo = F, out.width = "50%", fig.cap = "A visual representation of what the pivot_wider operation looks like in practice."}
knitr::include_graphics("images/tidyr_pivot_wider.png")
```

<details><summary>In R, long-to-wide conversion operations are performed using `pivot_wider()`</summary>
```{r pivot-wider-demo}
table2 %>%
  pivot_wider(names_from = type, values_from = count)
```
</details>


<details><summary>In python, long-to-wide conversion operations are performed using `pd.pivot()`</summary>
```{python pivot-wider-demo-python}
table2 = r.table2

pd.pivot(table2, index = ['country', 'year'], columns = 'type', values = 'count')

# We can get rid of the index by adding a .reset_index() to the end of the command
pd.pivot(table2, index = ['country', 'year'], columns = 'type', values = 'count').reset_index()
```
</details>

### Try it out! {- .tryitout}

Let's work with the dog breed traits data to see if we can get it into long format and then back into wide format based on some specific criteria. 

```{r dog-breeds-data-r}
breed_traits <- read.csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2022/2022-02-01/breed_traits.csv') %>%
  # There's something funky with the spaces in this data frame... so make them ASCII
  # (this fixes the encoding issues)
  mutate(Breed = iconv(Breed, to = "ASCII//translit"))
```

```{python dog-breeds-data-py}
breed_traits = pd.read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2022/2022-02-01/breed_traits.csv')

breed_traits[breed_traits.Breed == 'Russell Terriers']

breed_traits.Breed[10]
```

You may remember that the breed trait data includes a number of 1-5 numeric variables indicating score on various dimensions such as affection, shedding, openness, and playfulness. 

**Task 1**: Take all of the 1-5 numeric variables in the dataset and make a long-format dataset. **Choose 5 breeds of your choice**. Then, using your dataset, plot each breed's score, with each dimension as a separate facet. 

Your code in ggplot2 would look something like this:

```{r, eval = F}
ggplot(long_data, aes(x = breed, y = value)) + geom_col() + facet_wrap(~variable)
```

And in plotnine, it would look something like this:

```{python, eval = F}
from plotnine import *
ggplot(long_data, aes(x = "breed", y = "value")) + geom_col() + facet_wrap('variable')
```


<details><summary>R solution</summary>

```{r tryitout-solution-r}
library(ggplot2)
library(dplyr)
library(tidyr)

breed_traits %>%
  filter(gsub(" ", '', Breed) %in% c("Beagles", "Dachshunds", "Samoyeds", "RussellTerriers", "LhasaApsos")) %>%
  # Remove variables that aren't 1-5
  pivot_longer(-c(Breed, Coat.Type, Coat.Length), names_to = "Trait", values_to = "value") %>%
  ggplot(aes(x = Breed, y = value)) + geom_col() + facet_wrap(~Trait)

```

</details>
