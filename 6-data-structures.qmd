# Data Structures

```{r include = F}
# Need an r chunk to use the R engine, otherwise defaults to
# jupyter even with the flag set in _quarto.yml
c()
knitr::opts_chunk$set(collapse = T, message = F)
```

## Aside: Data Pipes {-}

Pipes are useful items for moving things from one place to another. In data programming, pipes are operators that let us move data around. In R, we have two primary pipes that are similar (you may see both used if you google for code online). Any R version after 4.1 has a built-in pipe, `|>`; the `tidyverse` libraries use a pipe from the `magrittr` package, `%>%`.

For right now, it's ok to think of the two pipes as essentially the same (but you can read about the differences [here](https://www.infoworld.com/article/3621369/use-the-new-r-pipe-built-into-r-41.html)).

Fundamentally, a pipe allows you to take a function `b()` and apply it to `x`, like `b(x)`, but write it as `x |> b()` or `x %>% b()`. This is particularly useful in cases where there are multiple sequential analysis steps, because where in regular notation you have to read the functions from the inside out to understand the sequential steps, with pipes, you have a clear step-by-step list of the order of operations.


In Python, there is a `pipe` function in the Pandas library that works using `.pipe(function)` notation. You can see [this example](https://stackoverflow.com/a/31037901) for more information. From what I've seen reading code online, however, pipes are less commonly used in Python code than they are in R code. That's ok - languages have different conventions, and it is usually best to adopt the convention of the language you're working in so that your code can be read, run, and maintained by others more easily.


::: tryitout

<details><summary>Use the `rnorm` function in R to generate 100 draws from a standard normal distribution, then use the pipe to calculate the mean.</summary>

```{r, collapse = T}
library(dplyr) # load the pipe %>%

rnorm(100) %>%
  mean()

rnorm(100) |> mean()
```

</details>

<details><summary>Calculate the mean of 100 random normal variables in python.</summary>


```{python, collapse = T}
import numpy as np
import pandas as pd

nums = pd.Series(np.random.normal(size = 100))
nums.mean()
```

The conclusion here is that it's far easier to not use the pipe in python because the `.function` notation that python uses mimics the step-by-step approach of pipes in R even without using the actual pipe function. When you use data frames instead of Series, you *might* start using the pipe, but only in some circumstances.

</details>

:::


## Motivation: Working with Multiple Vectors
<!-- data frames in R and Pandas -->

In the previous chapter, we talked about homogeneous structures: arrangements of data, like vectors and matrices, where every entry in the larger structure has the same type. In this chapter, we'll be talking about the root of most data science analysis projects: the data frame.

Like an excel spreadsheet, data frames are arrangements of data in columns and rows.

This format has two main restrictions:

- Every entry in each column must have the same data type
- Every column must have the same number of rows

![A lego data frame of 4 columns and 12 rows. Each column is a separate color hue (data type), with slight variations in the hue of each individual bricks.](images/lego-data-frame.png)

The picture above shows a data frame of 4 columns, each with a different data type (brick size/hue). The data frame has 12 rows. This picture may look similar to one that we used to show logical indexing in the last chapter, and that is not a coincidence. You can get everything from a data frame that you would get from a collection of 4 separate vectors... but there are advantages to keeping things in a data frame instead.


In the previous chapter, we learned how to make different vectors in R, numpy, and pandas. Consider for a moment https://worldpopulationreview.com/states, which lists the population of each state. You can find this dataset in CSV form [here](https://raw.githubusercontent.com/srvanderplas/Stat151/main/data/population2022.csv).

::: ex

<details><summary>Multiple vectors in Python</summary>
(I'm going to cheat and read this in using pandas functions we haven't learned yet to demonstrate why this stuff matters.)

```{python read-state-pops}
import pandas as pd

data = pd.read_html("https://worldpopulationreview.com/states")[0]
list(data.columns) # get names

# Create a few population series
population2022 = pd.Series(data['2022 Population'].values, index = data['State'].values)
population2021 = pd.Series(data['2021 Population'].values, index = data['State'].values)
population2010 = pd.Series(data['2010 Census'].values, index = data['State'].values)
```

Suppose that we want to sort each population vector by the population in that year.

```{python read-state-pops2, dependson = 'read-state-pops'}
import pandas as pd
data = pd.read_html("https://worldpopulationreview.com/states")[0]

population2022 = pd.Series(data['2022 Population'].values, index = data['State'].values).sort_values()
population2021 = pd.Series(data['2021 Population'].values, index = data['State'].values).sort_values()
population2010 = pd.Series(data['2010 Census'].values, index = data['State'].values).sort_values()

population2022.head()
population2021.head()
population2010.head()
```

The only problem is that by doing this, we've now lost the ordering that matched across all 3 vectors. Pandas Series are great for this, because they use labels that allow us to reconstitute which value corresponds to which label, but in R or even in numpy arrays, vectors don't inherently come with labels. In these situations, sorting by one value can actually destroy the connection between two vectors!

</details>

:::

::: ex

<details><summary>Vector-based analysis in R</summary>

```{r}
df <- read.csv("https://raw.githubusercontent.com/srvanderplas/Stat151/main/data/population2022.csv")

# Use vectors instead of the data frame
state <- df$State
pop2022 <- df$Pop
pop2021 <- df$Pop2021
pop2010 <- df$Pop2010

# Create a vector to index population in 2022 in order
order2022 <- order(pop2022)

# To keep variables together, we have to do things like this:
head(state[order2022])
head(pop2022[order2022])

# It makes more sense just to reorder the whole data frame:
head(df[order2022,])
```

</details>

:::


The primary advantage to data frames is that rows of data are kept together. Since we often think of a row of data as a single observation in a sample, this is an extremely important feature that makes data frames a huge improvement on a collection of vectors of the same length: it's much harder for observations in a single row to get shuffled around and mismatched!

In R, data frames are built in as type `data.frame`, though there are packages that provide other implementations of data frames that have additional features, such as the `tibble` package used in many other common packages. We will cover functions from both base R and the `tibble` package in this chapter.

In Python, we will use the `pandas` library, which is conventionally abbreviated `pd`. So before you use any data frames in python, you will need to add the following line to your code: `import pandas as pd`.

## Creating Data Frames

### From Scratch

If you want to create a data frame "from scratch" in either R or python, the easiest way to do so is to construct a list of vectors.


Data sourced from Wikipedia's [List of Oldest dogs](https://en.wikipedia.org/wiki/List_of_individual_dogs#Long-lived_dogs)

::: ex

<details><summary>Creating Data frames from scratch in R</summary>

```{r}
dog_names <- c("Bluey", "Bramble", "Chanel", "Max")
dog_ages <- c(29.41, 25, 21, 29.77)

# Using the data.frame function
data <- data.frame(Name = dog_names, Age = dog_ages)
data

# Using the tibble function
library(tibble)
data <- tibble(Name = dog_names, Age = dog_ages)
# Notice the difference in how the object is printed...
data

# Using the tribble function in the tibble package
data <- tribble(~Name, ~Age,
                "Bluey", 29.41,
                "Bramble", 25,
                "Chanel", 21,
                "Max", 29.77)
# This allows you to write out the data yourself in table format
# Column Names are indicated by putting ~ before the (bare) column name
data
```

</details>

:::


::: ex

<details><summary>Creating Data frames from scratch in python</summary>

```{python}
import pandas as pd

# Create a list of lists
data = [['Bluey', 29.41],
        ['Bramble', 25],
        ['Chanel', 21],
        ['Max', 29.77]]

data = pd.DataFrame(data, columns = ['Name', 'Age'])

# Create a dict with lists
data = {'Name': ['Bluey', 'Bramble', 'Chanel', 'Max'],
        'Age':  [29.41, 25, 21, 29.77]}

data = pd.DataFrame(data)
```

I am intentionally not discussing dictionaries (dicts) in Python at this point - my goal is to get you  up and running to do data analysis in Python with as little overhead as possible. If you are interested, you can read up on [dicts](https://www.py4e.com/html3/09-dictionaries) in Python 4 Everybody. We will hopefully find time to come back and discuss the finer points of lists, dicts, tuples, and other constructs later in the semester or in a subsequent course.

</details>

:::


### Reading in Data

One of the easier ways to create a data frame (rather than typing the whole thing in) is to read in data from somewhere else - a file, a table on a webpage, etc. We're not going to go into the finer points of this (you'll get into that in Stat 251, Data Wrangling), but it is important to at least know how to read in relatively nicely formatted data.

One nice source of (relatively neat) data is the [TidyTuesday github repository](https://github.com/rfordatascience/tidytuesday)^[Tidy Tuesday is a collaborative project where the R community gets together and explores a dataset, cleaning it, visualizing it, and generally working to collectively hone R skills together. You can find some very nice YouTube livestreams, as well as lots of examples using the [#tidytuesday twitter tag](https://twitter.com/search?q=%23tidytuesday).].

::: ex

<details><summary>
In Base R, we can read the data in using the `read.csv` function</summary>

```{r}
airmen <- read.csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2022/2022-02-08/airmen.csv')
head(airmen)
```

</details>


<details><summary>If we want instead to create a tibble, we can use the `readr` package's `read_csv` function, which is a bit more robust.</summary>

```{r read-in-data-r}
library(readr)
airmen <- read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2022/2022-02-08/airmen.csv')
head(airmen)
```

</details>

<details><summary>
In `pandas`, we can read the csv using `pd.read_csv`</summary>

```{python read-in-data-python}
import pandas as pd

airmen = pd.read_csv("https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2022/2022-02-08/airmen.csv")
airmen.head()
```

</details>

:::

## Working with Data Frames

### Summaries

Often, we want to know what a data frame contains. R and pandas both have easy summary methods for a data frame:

```{r}
summary(airmen)
```

Notice that the type of summary depends on the data type.

```{python}
airmen.describe()
```

There are ways to get pandas to describe other types of data that are not numeric, but I haven't completely figured out how they work yet. See the documentation [here](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.describe.html) for further details.

### Indexing

To access a subset of a data frame, we index by `[row, column]` in both languages (though in python we need a helper function tagged on the end of the object).

<details><summary>Indexing in python (lots of output)</summary>

```{python pandas-data-frame-indexing, error = T}
# .iloc allows for integer location-based indexing
airmen.iloc[0:4,] # leave the space for cols blank to get all columns
airmen.iloc[0:4,[0, 3, 5]] # include a vector of column indices

# .loc allows for using the row and column indexes
airmen.loc['0':'4',]
airmen.loc[0:4,'name':'first_name'] # columns between name and first_name
airmen.loc[0:4,[0,3,5]] # can't use position indexes with .loc
```

This uses a function of pandas we have not previously explored: slicing. Slicing in pandas acts very similar to R's seq method for integers, in that you can set your start and end points and use : between them. However, in python, the last index is the (non-inclusive) endpoint, so 0:3 will give you 0, 1, 2. If you want all columns after a certain index, you can use `x:`, where x is the starting index.

</details>

<details><summary>Indexing in R</summary>

```{r r-data-frame-indexing}
airmen[1:5, ]
airmen[1:5, c(1, 4, 6)]

airmen[1:5, c("name", "first_name")]
```

</details>


In R, we can also easily pull out a single column using the `$` method. Note that this gives us a vector (that is, we've lost the connection to the row index).

```{r r-pull-out-column-data-frame}
airmen$name[1:5]

head(airmen["name"]) # head() just gives us the first few rows
```

In python, we can also easily pull out a single column:

```{python pull-out-column-data-frame}
airmen.name
airmen['name']
```

The `df.column` notation, called **attribute access** only works in some circumstances: where the column name is not the same as a method (e.g. `min`) and is a valid Python identifier (so `df.1` does not work). When attribute access does not work, you can still access the column by name using `df['colname']` (standard indexing).

::: learn-more

- [Indexing in python with pandas](https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html) (Pandas documentation)
This includes good information on which indexing operations are most efficient and recommended for production code.

- [Slicing dataframes in R](https://bookdown.org/ndphillips/YaRrr/slicing-dataframes.html) - The Pirate's Guide to R

- [Indexing, Slicing, and Subsetting DataFrames in Python](https://datacarpentry.org/python-ecology-lesson/03-index-slice-subset/) - Visualization in Python for Ecologists

:::

### Row and Column Names

In both R and python, data frames have two sets of names: a set of row names, and a set of column names. In my experience, it is much more common to use column names in R and less common to actually use row names^[More advanced data-frame like structures, such as `tibbles`, actively discourage the use of row names.]; in Python it seems that people tend to use both sets of names frequently.

<details><summary>Row and Column Names in Python</summary>

Let's start with column names. Column names can be defined by creating a `Series` object (remember, that's just a fancy name for an indexed vector) and assigning it to the `df.columns` object, where `df` is the name of the data frame.

```{python pandas-column-names, error = T}
# Get index of column names
airmen.columns

# We can set the names using simple assignment
airmen.columns = pd.Series(['Name', 'Last', 'First', 'Graduation_Date', 'Graduation_Rank', 'Class', 'Graduated_From', 'Pilot_Type', 'Hometown', 'State', 'Aerial_Victory_Credits', 'Num_Aerial_Victory_Credits', 'Reported_Lost', 'Reported_Lost_Date', 'Reported_Lost_Location', 'Web_Profile'])

# Now the names are capitalized
airmen.columns
```


```{python pandas-row-names, error = T}
# Get index of row names
airmen.index # this structure has numeric row names
# we can access individual rows using the numeric index (iloc)
airmen.iloc[0]
# we can also access individual rows using the regular index (loc)
airmen.loc[0]
# this doesn't work because the row names are integers
airmen.loc['Adams, John H., Jr.']

# We can set row names using simple assignment
airmen.index = airmen.name

# Row names are changed
airmen.index # now the row name index is a string and we can look names up this way

# we can still access individual rows using the numeric index (iloc)
airmen.iloc[0]
# we can mo longer access individual rows using the regular index (loc)
# with a numeric value
airmen.loc[0]
# but because we set the row names to be the individuals actual names,
# we can use those in the .loc statement
airmen.loc['Adams, John H., Jr.']
```

When we select certain rows using the row names, we typically refer to the row names as the **key**.

</details>


::: learn-more

Read more about database keys [here](https://www.learncomputerscienceonline.com/database-keys/) if you are interested. This is material that we will cover in Stat 351, but it may be useful for you now if you are interested in learning to program more efficiently from the start.

:::

<details><summary> Row and Column Names in R</summary>

In R, column and row names are just normal vectors - no special data types here!

```{r r-column-names}
names(airmen)

# Set new column names
names(airmen) <- c('Name', 'Last', 'First', 'Graduation_Date', 'Graduation_Rank', 'Class', 'Graduated_From', 'Pilot_Type', 'Hometown', 'State', 'Aerial_Victory_Credits', 'Num_Aerial_Victory_Credits', 'Reported_Lost', 'Reported_Lost_Date', 'Reported_Lost_Location', 'Web_Profile')

# Using new names
airmen$Name[1:5]
```

If we want to set row names in R, we can try the obvious approach:
```{r r-row-names, error = T}
rownames(airmen) <- airmen$Name
```

But this runs into trouble, since we have some duplicate names. We can see which names are duplicates by using the `table` command combined with `sort` and `head` to truncate the output. I'm going to use the `pipe` command, `|>`, to separate these steps. This is equivalent to `head(sort(table(airmen$Name), decreasing = T))` but is much easier to read since it can be read as a "recipe" of steps.

```{r duplicate-rownames-airmen-r, error = T}
table(airmen$Name) |>
  sort(decreasing = T) |>
  head()
```

R requires rownames to be unique, so we are better off with some other identifier that we don't have here (SSN, military ID number, etc.) that is guaranteed to be unique. Since we don't have that kind of information, we really don't get any advantage by setting the rownames in R.

</details>

### Creating New Columns

In both Python and R, it is very easy to add new (derived) columns to a data frame, using methods similar to how you access data from a pre-existing column:

```{r}
airmen$initials <- paste0(substr(airmen$First, 1, 1), substr(airmen$Last, 1, 1))
head(airmen$initials)
```

```{python}
airmen['initials'] = airmen['First'].str.slice(0,1) + airmen['Last'].str.slice(0,1)
airmen['initials'][0:7]
```

Another way to create new variables in R involves the use of the `dplyr` package. There are at least 2 advantages to using this package for these types of tasks:

1. There is a consistent way to call each function and engage with the data (this API - application programming interface - is designed around using the pipe, `%>%` discussed above)
2. You don't have to reference the data frame name and the column name using `df$colname`; instead, you use the function on the data frame and work with "bare" column names inside that function.

```{r}
library(dplyr)

airmen <- airmen %>%
  mutate(initials = paste0(substr(First, 1, 1), substr(Last, 1, 1)))
select(airmen, 1:3, initials) # Select lets us choose to only show some columns
```

Notice that by running mutate on the data frame, we automatically get a tibble back.


You can do a similar trick with the `.assign` function in pandas, but unlike in R, you still have to reference the dataframe object within the .assign function.

```{python}
airmen.assign(
  initials = airmen['First'].str.slice(0,1) + airmen['Last'].str.slice(0,1)
)
```


### Subsets of Rows

Another major operation commonly performed on data frames is to choose only a certain set of rows, either randomly or using a logical condition.

<details><summary>In base R, we would use the subset() function:</summary>

```{r}
subset(airmen, Last == "Young")
```

</details>

<details><summary>In python, we use the `.query()` function:</summary>

```{python}
airmen.query('Last == "Young"')
```

Note that here, the column name (and logical condition) are in quotes, but you don't have to reference the data frame name.
</details>

<details><summary>In `dplyr`, we use the `filter` function:</summary>

```{r}
airmen %>%
  filter(Last == "Young")
```

</details>

We can also sample from a data frame. This can be useful when working with a large dataset, or when simulating to determine how a method performs on some data.

For simplicity, I'm going to primarily show you the dplyr and pandas equivalents - it is possible to do this in base R, but it's much easier to do in `dplyr`.

<details><summary>Sampling in R</summary>

```{r}
airmen %>% sample_frac(.01)
airmen %>% sample_n(5)
```

</details>

<details><summary>Sampling rows is similarly easy in python:</summary>

```{python}
airmen.sample(frac=.01)
airmen.sample(n = 5)
```

</details>

::: tryitout

### Try it (all) Out!

Let's look at a dataset of dog breed rankings (1 = low, 5 = high) for different traits. We can read in this data using the following code:

```{r}
breed_traits <- read.csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2022/2022-02-01/breed_traits.csv')
```


```{python}
breed_traits = pd.read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2022/2022-02-01/breed_traits.csv')
```


Can you complete the following tasks?

1. Pull out any dogs that have "Terrier" in the name.
Hint: [Testing with strings in python](https://pandas.pydata.org/pandas-docs/stable/user_guide/text.html#testing-for-strings-that-match-or-contain-a-pattern), [Using `grep` and `grepl` in R](https://www.statology.org/grep-vs-grepl-r/)

2. Create a data frame of all dogs who are 4 or 5 on "Affectionate with Family" and name it good_with_family. Make sure you keep all of the columns in the original data frame.

3. Create a data frame with all variables relating to coat (shedding level, coat type, coat length, grooming frequency) as well as the dog breed. Make sure you keep all rows, but only include the necessary columns.

4. Draw a random sample of 10 dogs from your dataset.

5. Create a new variable, named mess, that is the product of the dog's shedding level and their drooling level. (It's probably a bad idea to multiply categorical variables, but in this case we're going to go with it.) Summarize this numeric variable.

<details><summary>Solutions (R)</summary>

```{r}
library(dplyr) # data frame manipulations
library(stringr) # string comparison functions in tidyverse

# 1: Terriers
terrorists <- breed_traits[grepl("Terrier", breed_traits$Breed),]
terrorists2 <- breed_traits %>%
  filter(str_detect(Breed, "Terrier"))

# 2: Good with Family
good_with_family <- breed_traits[breed_traits$Affectionate.With.Family > 3,]
good_with_family2 <- breed_traits %>%
  filter(Affectionate.With.Family > 3)

# 3: Coat variables
coat <- breed_traits[,c(1, 4:5, 7:8)] # count column by column
coat2 <- breed_traits %>%
  select(Breed, matches(c("Coat", "Grooming", "Shedding"))) # tidy way
coat3 <- breed_traits[,grepl("Coat|Grooming|Shedding|Breed", names(breed_traits))] # match string names

# 4: random sample of 10 dogs
sample_dogs <- breed_traits[sample(1:nrow(breed_traits), 10),] # base R way
sample_dogs2 <- breed_traits %>% sample_n(10) # tidy way

# 5: mess
breed_traits$mess <- breed_traits$Drooling.Level * breed_traits$Shedding.Level
breed_traits <- breed_traits %>%
  mutate(mess2 = Drooling.Level*Shedding.Level)

summary(breed_traits$mess)
breed_traits %>% select(mess2) %>% summary()
```

</details>


<details><summary>Solutions (python) </summary>

```{python}
# 1: Terriers
terrorists = breed_traits.loc[breed_traits.Breed.str.match(r".*Terrier.*"),]

# 2: Good with Family
good_with_family = breed_traits.query("`Affectionate With Family` > 3")
good_with_family['Affectionate With Family'].min() # just checking

# 3: Coat variables
coat = breed_traits.loc[:,["Breed", "Shedding Level", "Coat Grooming Frequency", "Coat Type", "Coat Length"]]
coat2 = breed_traits.iloc[:,breed_traits.columns.str.match(r"Breed|Coat|Shedding")]

# 4: random sample of 10 dogs
sample_dogs = breed_traits.sample(n = 10)

# 5: mess
breed_traits['mess'] = breed_traits['Drooling Level'] * breed_traits['Shedding Level']
breed_traits.mess.describe
breed_traits.mess.min()
breed_traits.mess.max()
```

</details>


## Basic Plotting Examples

Now that you can read data in to R and python and define new variables, you can create plots! We'll focus a bit more on this later in the class, but for now, I'd like to take a few minutes to explain how to make (basic) plots in R (with `ggplot2`) and in python (with `plotnine`, which is a ggplot2 clone).

Let's work with Historically Black College and University enrollment in this example:

```{r}
hbcu_all <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2021/2021-02-02/hbcu_all.csv')

library(ggplot2)
```

```{python}
from plotnine import *
import pandas as pd

hbcu_all <- pd.read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2021/2021-02-02/hbcu_all.csv')

```

ggplot2 and plotnine work with data frames. If you pass a data frame in as the data argument, you can refer to columns in that data with "bare" column names:

```{r}

ggplot(hbcu_all, aes(x = Year, y = `4-year`)) + geom_line() +
  ggtitle("4-year HBCU College Enrollment")

```

:::
>>>>>>> cfaf4a0ea04a2604c1f45d8481e3b25f59789cf0
